{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras.models\n",
      "  Downloading keras_models-0.0.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: keras in /Users/yasmine/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from keras.models) (2.13.1)\n",
      "Requirement already satisfied: numpy in /Users/yasmine/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from keras.models) (1.24.3)\n",
      "Collecting spacy (from keras.models)\n",
      "  Downloading spacy-3.8.2.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m301.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[120 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting cython<3.0,>=0.25\n",
      "  \u001b[31m   \u001b[0m   Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting cymem<2.1.0,>=2.0.2\n",
      "  \u001b[31m   \u001b[0m   Downloading cymem-2.0.10.tar.gz (10 kB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Collecting preshed<3.1.0,>=3.0.2\n",
      "  \u001b[31m   \u001b[0m   Using cached preshed-3.0.9-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  \u001b[31m   \u001b[0m   Downloading murmurhash-1.0.11.tar.gz (13 kB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Collecting thinc<8.4.0,>=8.3.0\n",
      "  \u001b[31m   \u001b[0m   Downloading thinc-8.3.2.tar.gz (193 kB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[78 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cython<3.0,>=0.25\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting murmurhash<1.1.0,>=1.0.2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached murmurhash-1.0.11.tar.gz (13 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cymem<2.1.0,>=2.0.2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached cymem-2.0.10.tar.gz (10 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting preshed<3.1.0,>=3.0.2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached preshed-3.0.9-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting blis<1.1.0,>=1.0.0\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Downloading blis-1.0.2.tar.gz (3.6 MB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/3.6 MB\u001b[0m \u001b[31m468.4 kB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/3.6 MB\u001b[0m \u001b[31m468.4 kB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/3.6 MB\u001b[0m \u001b[31m502.5 kB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/3.6 MB\u001b[0m \u001b[31m502.5 kB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.6 MB\u001b[0m \u001b[31m535.2 kB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.6 MB\u001b[0m \u001b[31m535.2 kB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/3.6 MB\u001b[0m \u001b[31m554.5 kB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/3.6 MB\u001b[0m \u001b[31m554.5 kB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/3.6 MB\u001b[0m \u001b[31m592.2 kB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/3.6 MB\u001b[0m \u001b[31m625.0 kB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.6 MB\u001b[0m \u001b[31m685.9 kB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/3.6 MB\u001b[0m \u001b[31m740.0 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/3.6 MB\u001b[0m \u001b[31m740.0 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/3.6 MB\u001b[0m \u001b[31m740.0 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m2.6/3.6 MB\u001b[0m \u001b[31m691.5 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.9/3.6 MB\u001b[0m \u001b[31m718.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.9/3.6 MB\u001b[0m \u001b[31m718.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m3.1/3.6 MB\u001b[0m \u001b[31m715.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m3.4/3.6 MB\u001b[0m \u001b[31m719.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m3.4/3.6 MB\u001b[0m \u001b[31m719.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m691.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[?25h  Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cython>=0.25\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached Cython-3.0.11-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31mERROR: Ignored the following versions that require a different python version: 1.25.0 Requires-Python >=3.9; 1.25.1 Requires-Python >=3.9; 1.25.2 Requires-Python >=3.9; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9; 1.26.2 Requires-Python >=3.9; 1.26.3 Requires-Python >=3.9; 1.26.4 Requires-Python >=3.9; 2.0.0 Requires-Python >=3.9; 2.0.1 Requires-Python >=3.9; 2.0.2 Requires-Python >=3.9; 2.1.0 Requires-Python >=3.10; 2.1.0rc1 Requires-Python >=3.10; 2.1.1 Requires-Python >=3.10; 2.1.2 Requires-Python >=3.10; 2.1.3 Requires-Python >=3.10; 2.2.0 Requires-Python >=3.10; 2.2.0rc1 Requires-Python >=3.10; 2.2.1 Requires-Python >=3.10; 75.4.0 Requires-Python >=3.9; 75.5.0 Requires-Python >=3.9; 75.6.0 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1152 images belonging to 17 classes.\n",
      "Found 288 images belonging to 17 classes.\n",
      "Found 360 images belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14990161 (57.18 MB)\n",
      "Trainable params: 13842705 (52.81 MB)\n",
      "Non-trainable params: 1147456 (4.38 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "36/36 [==============================] - 73s 2s/step - loss: 3.6819 - accuracy: 0.0807 - val_loss: 3.3849 - val_accuracy: 0.0625 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 3.4864 - accuracy: 0.0911 - val_loss: 5.6912 - val_accuracy: 0.0729 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 3.1247 - accuracy: 0.1389 - val_loss: 4.7702 - val_accuracy: 0.1042 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "36/36 [==============================] - 72s 2s/step - loss: 3.0135 - accuracy: 0.1406 - val_loss: 4.4543 - val_accuracy: 0.0833 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "36/36 [==============================] - 72s 2s/step - loss: 2.8460 - accuracy: 0.1606 - val_loss: 3.0560 - val_accuracy: 0.1493 - lr: 5.0000e-05\n",
      "Epoch 6/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 2.5739 - accuracy: 0.2023 - val_loss: 2.2909 - val_accuracy: 0.2153 - lr: 5.0000e-05\n",
      "Epoch 7/30\n",
      "36/36 [==============================] - 70s 2s/step - loss: 2.3494 - accuracy: 0.2405 - val_loss: 2.5957 - val_accuracy: 0.2014 - lr: 5.0000e-05\n",
      "Epoch 8/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 2.2099 - accuracy: 0.2882 - val_loss: 2.2290 - val_accuracy: 0.2222 - lr: 5.0000e-05\n",
      "Epoch 9/30\n",
      "36/36 [==============================] - 70s 2s/step - loss: 2.0019 - accuracy: 0.3542 - val_loss: 3.2877 - val_accuracy: 0.1840 - lr: 5.0000e-05\n",
      "Epoch 10/30\n",
      "36/36 [==============================] - 72s 2s/step - loss: 2.0207 - accuracy: 0.3333 - val_loss: 2.1532 - val_accuracy: 0.3021 - lr: 5.0000e-05\n",
      "Epoch 11/30\n",
      "36/36 [==============================] - 73s 2s/step - loss: 1.7932 - accuracy: 0.3950 - val_loss: 2.1575 - val_accuracy: 0.2639 - lr: 5.0000e-05\n",
      "Epoch 12/30\n",
      "36/36 [==============================] - 73s 2s/step - loss: 1.7339 - accuracy: 0.4253 - val_loss: 2.4817 - val_accuracy: 0.2674 - lr: 5.0000e-05\n",
      "Epoch 13/30\n",
      "36/36 [==============================] - 73s 2s/step - loss: 1.6987 - accuracy: 0.4288 - val_loss: 1.9158 - val_accuracy: 0.4201 - lr: 5.0000e-05\n",
      "Epoch 14/30\n",
      "36/36 [==============================] - 73s 2s/step - loss: 1.5326 - accuracy: 0.4774 - val_loss: 2.0736 - val_accuracy: 0.3646 - lr: 5.0000e-05\n",
      "Epoch 15/30\n",
      "36/36 [==============================] - 70s 2s/step - loss: 1.5446 - accuracy: 0.4731 - val_loss: 1.5177 - val_accuracy: 0.4583 - lr: 5.0000e-05\n",
      "Epoch 16/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 1.3410 - accuracy: 0.5477 - val_loss: 1.5917 - val_accuracy: 0.4479 - lr: 5.0000e-05\n",
      "Epoch 17/30\n",
      "36/36 [==============================] - 72s 2s/step - loss: 1.3048 - accuracy: 0.5503 - val_loss: 1.5340 - val_accuracy: 0.4792 - lr: 5.0000e-05\n",
      "Epoch 18/30\n",
      "36/36 [==============================] - 75s 2s/step - loss: 1.2790 - accuracy: 0.5530 - val_loss: 1.5465 - val_accuracy: 0.4965 - lr: 5.0000e-05\n",
      "Epoch 19/30\n",
      "36/36 [==============================] - 75s 2s/step - loss: 1.0680 - accuracy: 0.6267 - val_loss: 1.3126 - val_accuracy: 0.5486 - lr: 2.5000e-05\n",
      "Epoch 20/30\n",
      "36/36 [==============================] - 71s 2s/step - loss: 1.0282 - accuracy: 0.6380 - val_loss: 1.1561 - val_accuracy: 0.5833 - lr: 2.5000e-05\n",
      "Epoch 21/30\n",
      "14/36 [==========>...................] - ETA: 39s - loss: 0.8707 - accuracy: 0.6875"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = \"./Celebrity Faces Dataset/\"  # Update with the path to your extracted dataset\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# Preprocess dataset\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze the last few layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Class Weights\n",
    "class_weights = compute_class_weight('balanced', classes=list(range(num_classes)), y=train_generator.classes)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model_checkpoint_{epoch:02d}.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    class_weight={i: class_weights[i] for i in range(len(class_weights))},\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    class_weight={i: class_weights[i] for i in range(len(class_weights))},\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
    "print(f'\\nTest accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the trained CNN model\n",
    "model = load_model('model_checkpoint_50.h5')  # Load the best model checkpoint\n",
    "\n",
    "# Function to extract face embeddings from an image\n",
    "def get_face_embeddings(image, model):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    embeddings = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = image[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (128, 128))\n",
    "        face_roi = np.expand_dims(face_roi, axis=0) / 255.0\n",
    "\n",
    "        # Extract embedding using the model\n",
    "        embedding = model.predict(face_roi)[:, :-2]  # Exclude the final classification layers\n",
    "\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Load known face embeddings and labels (replace with your actual data)\n",
    "known_embeddings = np.load('known_embeddings.npy')\n",
    "known_labels = np.load('known_labels.npy')\n",
    "\n",
    "# Function to recognize a face in a new image\n",
    "def recognize_face(image, model):\n",
    "    embeddings = get_face_embeddings(image, model)\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        return \"No face detected\"\n",
    "\n",
    "    distances = np.linalg.norm(known_embeddings - embeddings[0], axis=1)\n",
    "    best_match_index = np.argmin(distances)\n",
    "    predicted_label = known_labels[best_match_index]\n",
    "\n",
    "    # Threshold for confidence\n",
    "    threshold = 0.5 \n",
    "    if distances[best_match_index] <= threshold:\n",
    "        return f\"Recognized as: {predicted_label}\"\n",
    "    else:\n",
    "        return \"Unknown person\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# Example usage\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "result = recognize_face(image, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1152 images belonging to 17 classes.\n",
      "Found 288 images belonging to 17 classes.\n",
      "Found 360 images belonging to 17 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 77\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n",
      "\u001b[0;32m---> 77\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mSequential([\n",
      "\u001b[1;32m     78\u001b[0m     base_model,\n",
      "\u001b[1;32m     79\u001b[0m     GlobalAveragePooling2D(),\n",
      "\u001b[1;32m     80\u001b[0m     BatchNormalization(),\n",
      "\u001b[1;32m     81\u001b[0m     Dense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n",
      "\u001b[1;32m     82\u001b[0m     BatchNormalization(),\n",
      "\u001b[1;32m     83\u001b[0m     Dropout(\u001b[38;5;241m0.3\u001b[39m),\n",
      "\u001b[1;32m     84\u001b[0m     Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     85\u001b[0m ])\n",
      "\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[1;32m     88\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m),\n",
      "\u001b[1;32m     89\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     90\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = \"./Celebrity Faces Dataset/\"  # Update with the path to your extracted dataset\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# Preprocess dataset\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze the last few layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Class Weights\n",
    "class_weights = compute_class_weight('balanced', classes=list(range(num_classes)), y=train_generator.classes)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model_checkpoint_{epoch:02d}.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    class_weight={i: class_weights[i] for i in range(len(class_weights))},\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    class_weight={i: class_weights[i] for i in range(len(class_weights))},\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
    "print(f'\\nTest accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the trained CNN model\n",
    "model = load_model('model_checkpoint_50.h5')  # Load the best model checkpoint\n",
    "\n",
    "# Function to extract face embeddings from an image\n",
    "def get_face_embeddings(image, model):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    embeddings = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = image[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (128, 128))\n",
    "        face_roi = np.expand_dims(face_roi, axis=0) / 255.0\n",
    "\n",
    "        # Extract embedding using the model\n",
    "        embedding = model.predict(face_roi)[:, :-2]  # Exclude the final classification layers\n",
    "\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Load known face embeddings and labels (replace with your actual data)\n",
    "known_embeddings = np.load('known_embeddings.npy')\n",
    "known_labels = np.load('known_labels.npy')\n",
    "\n",
    "# Function to recognize a face in a new image\n",
    "def recognize_face(image, model):\n",
    "    embeddings = get_face_embeddings(image, model)\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        return \"No face detected\"\n",
    "\n",
    "    distances = np.linalg.norm(known_embeddings - embeddings[0], axis=1)\n",
    "    best_match_index = np.argmin(distances)\n",
    "    predicted_label = known_labels[best_match_index]\n",
    "\n",
    "    # Threshold for confidence\n",
    "    threshold = 0.5 \n",
    "    if distances[best_match_index] <= threshold:\n",
    "        return f\"Recognized as: {predicted_label}\"\n",
    "    else:\n",
    "        return \"Unknown person\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
